{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp=en_core_web_sm.load()\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO \n",
    "import re\n",
    "import pandas\n",
    "from pandas import ExcelWriter\n",
    "import datetime\n",
    "from tkinter import filedialog\n",
    "from tkinter import Button, Tk, HORIZONTAL\n",
    "from tkinter.ttk import Progressbar\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional parameter PAGES can restrict which pages to process\n",
    "def convert_pdf_to_txt(path, pages=None):\n",
    "    if not pages:\n",
    "        pagenums = set()\n",
    "    else:\n",
    "        pagenums = set(pages)\n",
    "    \n",
    "    #Instantiate the PDFminer objects\n",
    "    output = StringIO()\n",
    "    manager = PDFResourceManager()\n",
    "    converter = TextConverter(manager, output, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(manager, converter)\n",
    "    \n",
    "    infile = open(path, 'rb') #open the file for read in binary mode\n",
    "    \n",
    "    for page in PDFPage.get_pages(infile, pagenums):\n",
    "        #iterate with the pdf interpreter through the pdf pages\n",
    "        interpreter.process_page(page)\n",
    "    \n",
    "    #Close the files and converters\n",
    "    infile.close()\n",
    "    converter.close()\n",
    "    text = output.getvalue()\n",
    "    output.close()\n",
    "    text=str(text)\n",
    "    text=text.replace(\"\\\\n\",\" \")\n",
    "    text=text.replace(\"\\n\",\" \")\n",
    "    text=text.replace(\" \\x0c \",\" \")\n",
    "    text=text.lower()\n",
    "    return text   #return the text as str\n",
    "\n",
    "def removeques(text):\n",
    "    text=re.sub(r\"\\bq1. why should you be hired for this internship?\\b\",\" \" ,text)\n",
    "    text=re.sub(r\"\\bq4. which is your strongest open source tool among sas, r, tableau, python?\\b\",\" \" ,text)\n",
    "    text=re.sub(r\"\\bq3. how will you rate yourself on sql knowledge?\\b\",\" \" ,text)\n",
    "    return text\n",
    "data=pd.read_csv('datascience_ontology.csv')\n",
    "def createProfile(file):\n",
    "    text=convert_pdf_to_txt(file)\n",
    "    text=removeques(text)\n",
    "    #print(text)\n",
    "    keyword_dict=pd.read_csv(\"datascience_ontology.csv\")\n",
    "    \n",
    "    time_word=[nlp(text) for text in keyword_dict[\"TimeSeries\"].dropna(axis=0)]\n",
    "    nlp_word=[nlp(text) for text in keyword_dict[\"NLP\"].dropna(axis=0)]\n",
    "    ml_word=[nlp(text) for text in keyword_dict[\"Machine Learning\"].dropna(axis=0)]\n",
    "    python_word=[nlp(text) for text in keyword_dict[\"Python\"].dropna(axis=0)]\n",
    "    r_word=[nlp(text) for text in keyword_dict[\"R\"].dropna(axis=0)]\n",
    "    dl_word=[nlp(text) for text in keyword_dict[\"Deep Learning\"].dropna(axis=0)]\n",
    "    BI_word=[nlp(text) for text in keyword_dict[\"BI Tools\"].dropna(axis=0)]\n",
    "    dataeng_word=[nlp(text) for text in keyword_dict[\"Data Engineering\"].dropna(axis=0)]\n",
    "    big_word=[nlp(text) for text in keyword_dict[\"BigData\"].dropna(axis=0)]\n",
    "    \n",
    "    matcher=PhraseMatcher(nlp.vocab)\n",
    "    matcher.add('TimeSeries',None,*time_word)\n",
    "    matcher.add('BI_Tools',None,*BI_word)\n",
    "    matcher.add('R',None,*r_word)\n",
    "    matcher.add('NLP',None,*nlp_word)\n",
    "    matcher.add('Bigdata',None,*big_word)\n",
    "    matcher.add('Machine_learning',None,*ml_word)\n",
    "    matcher.add('Python',None,*python_word)\n",
    "    matcher.add('DeepLearning',None,*dl_word)\n",
    "    matcher.add('DataEngineering',None,*dataeng_word)\n",
    "    doc=nlp(text)\n",
    "    \n",
    "    d=[]\n",
    "    matches=matcher(doc)\n",
    "    for match_id,start,end in matches:\n",
    "        rule_id=nlp.vocab.strings[match_id]\n",
    "        span=doc[start:end]\n",
    "        d.append((rule_id,span.text))\n",
    "    keywords=\"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
    "    \n",
    "    df=pd.read_csv(StringIO(keywords),names=['Keywords_list'])\n",
    "    \n",
    "    df1=pd.DataFrame(df.Keywords_list.str.split(' ',1).tolist(),columns=['Subject','Keyword'])\n",
    "    df2=pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns=['Keyword','Count'])\n",
    "    df3=pd.concat([df1['Subject'],df2['Keyword'],df2['Count']],axis=1)\n",
    "    df3['Count']=df3['Count'].apply(lambda x:x.rstrip(\")\"))\n",
    "    #print(df)\n",
    "    #print(df1)\n",
    "    #print(df2)\n",
    "    #print(df3)\n",
    "    base=os.path.basename(file)\n",
    "    filename=os.path.splitext(base)[0]\n",
    "    name = filename.split('_')\n",
    "    name2 = name[0]\n",
    "    name2 = name2.lower()\n",
    "    ## converting str to dataframe\n",
    "    name3 = pd.read_csv(StringIO(name2),names = ['Candidate Name'])\n",
    "    \n",
    "    dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
    "    #return text\n",
    "    return(dataf)\n",
    "def get_report():\n",
    "    #mypath=folder\n",
    "    #onlyfiles=[os.path.join(mypath,f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath,f))]\n",
    "    #print(\"success\")\n",
    "    currentDT = datetime.datetime.now()\n",
    "    currentDT=currentDT.strftime(\"%Y%m%d%H%M%S\")\n",
    "    final_database=pd.DataFrame()\n",
    "    i = 0 \n",
    "\n",
    "    while i < len(onlyfiles):\n",
    "        file = onlyfiles[i]\n",
    "        dat = createProfile(file)\n",
    "        final_database = final_database.append(dat)\n",
    "        i +=1\n",
    "    final_database2 = final_database['Keyword'].groupby([final_database['Candidate Name'], final_database['Subject']]).count().unstack()\n",
    "    final_database2.reset_index(inplace = True)\n",
    "    final_database2.fillna(0,inplace=True)\n",
    "    #print(final_database2)\n",
    "    writer = ExcelWriter(\"CandidateSkillExcel\"+str(currentDT)+\".xlsx\")\n",
    "    final_database2.to_excel(writer,'resume_skill_Sheet')\n",
    "    writer.save()\n",
    "    #final_database2 = final_database['Keyword'].groupby([final_database['Candidate Name'], final_database['Subject']]).count().unstack()\n",
    "    #final_database2.reset_index(inplace = True)\n",
    "    #final_database2.fillna(0,inplace=True)\n",
    "    new_data = final_database2.iloc[:,1:]\n",
    "    new_data.index = final_database2['Candidate Name']\n",
    "    #execute the below line if you want to see the candidate profile in a csv format\n",
    "    sample2=new_data.to_csv(\"CandidateSkillSaved\"+str(currentDT)+\".csv\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    ax = new_data.plot.barh(title=\"Resume keywords by category\", legend=False, figsize=(30,17), stacked=True)\n",
    "    labels = []\n",
    "    for j in new_data.columns:\n",
    "        for i in new_data.index:\n",
    "            label = str(j)+\": \" + str(new_data.loc[i][j])\n",
    "            labels.append(label)\n",
    "    patches = ax.patches\n",
    "    for label, rect in zip(labels, patches):\n",
    "        width = rect.get_width()\n",
    "        if width > 0:\n",
    "            x = rect.get_x()\n",
    "            y = rect.get_y()\n",
    "            height = rect.get_height()\n",
    "            ax.text(x + width/2., y + height/2., label, ha='center', va='center')\n",
    "    plt.savefig(\"Resume_Statistic\"+str(currentDT)+\".png\")\n",
    "    #print(\"Saved sucessfully\")\n",
    "    return \"success\"\n",
    "#final_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-04 15:56:41.942265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20190304155641'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentDT = datetime.datetime.now()\n",
    "\n",
    "print(currentDT)\n",
    "currentDT.strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "normal\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter.ttk import *\n",
    "\n",
    "master = Tk()\n",
    "master.geometry(\"500x200\")\n",
    "Label(master, text=\"Selected Folder is:\").grid(row=1)\n",
    "def myfunc():\n",
    "    s=str(btn['state'])\n",
    "    print(s)\n",
    "    inputValue=\"Loading...\"\n",
    "    txt=get_report()\n",
    "    print(s)\n",
    "    if s == \"active\":\n",
    "        label = Label(master, text=\"Loading...\").grid(row=3)\n",
    "    \n",
    "    #if txt==\"success\":\n",
    "    #    label = Label(master, text=\"Action completed!Reports generated successfully\").grid(row=2)\n",
    "btn = Button(master, text=\"Get Report\", command=myfunc)\n",
    "\n",
    "e1 = Entry(master,width=50)\n",
    "#e2 = Entry(master)\n",
    "folder_selected = filedialog.askdirectory()\n",
    "fold=str(folder_selected)\n",
    "\n",
    "e1.insert(0, fold)\n",
    "#print(btn.state)\n",
    "e1.grid(row=1, column=1)\n",
    "btn.grid(row=1,column=3)\n",
    "#e2.grid(row=1, column=1)\n",
    "mypath=folder_selected\n",
    "onlyfiles=[os.path.join(mypath,f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath,f))]\n",
    "\n",
    "mainloop( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
