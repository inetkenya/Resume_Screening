{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp=en_core_web_sm.load()\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO \n",
    "import re\n",
    "import pandas\n",
    "from pandas import ExcelWriter\n",
    "import datetime\n",
    "from tkinter import filedialog\n",
    "from tkinter import Button, Tk, HORIZONTAL\n",
    "from tkinter.ttk import Progressbar\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional parameter PAGES can restrict which pages to process\n",
    "def convert_pdf_to_txt(path, pages=None):\n",
    "    if not pages:\n",
    "        pagenums = set()\n",
    "    else:\n",
    "        pagenums = set(pages)\n",
    "    \n",
    "    #Instantiate the PDFminer objects\n",
    "    output = StringIO()\n",
    "    manager = PDFResourceManager()\n",
    "    converter = TextConverter(manager, output, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(manager, converter)\n",
    "    \n",
    "    infile = open(path, 'rb') #open the file for read in binary mode\n",
    "    \n",
    "    for page in PDFPage.get_pages(infile, pagenums):\n",
    "        #iterate with the pdf interpreter through the pdf pages\n",
    "        interpreter.process_page(page)\n",
    "    \n",
    "    #Close the files and converters\n",
    "    infile.close()\n",
    "    converter.close()\n",
    "    text = output.getvalue()\n",
    "    output.close()\n",
    "    text=str(text)\n",
    "    text=text.replace(\"\\\\n\",\" \")\n",
    "    text=text.replace(\"\\n\",\" \")\n",
    "    text=text.replace(\" \\x0c \",\" \")\n",
    "    text=text.lower()\n",
    "    return text   #return the text as str\n",
    "\n",
    "def removeques(text):\n",
    "    text=re.sub(r\"\\bq1. why should you be hired for this internship?\\b\",\" \" ,text)\n",
    "    text=re.sub(r\"\\bq4. which is your strongest open source tool among sas, r, tableau, python?\\b\",\" \" ,text)\n",
    "    text=re.sub(r\"\\bq3. how will you rate yourself on sql knowledge?\\b\",\" \" ,text)\n",
    "    return text\n",
    "def createProfile(file,onto):\n",
    "    text=convert_pdf_to_txt(file)\n",
    "    text=removeques(text)\n",
    "    #print(text)\n",
    "    keyword_dict=pd.read_csv(str(onto))\n",
    "    \n",
    "    time_word=[nlp(text) for text in keyword_dict[\"TimeSeries\"].dropna(axis=0)]\n",
    "    nlp_word=[nlp(text) for text in keyword_dict[\"NLP\"].dropna(axis=0)]\n",
    "    ml_word=[nlp(text) for text in keyword_dict[\"Machine Learning\"].dropna(axis=0)]\n",
    "    python_word=[nlp(text) for text in keyword_dict[\"Python\"].dropna(axis=0)]\n",
    "    r_word=[nlp(text) for text in keyword_dict[\"R\"].dropna(axis=0)]\n",
    "    dl_word=[nlp(text) for text in keyword_dict[\"Deep Learning\"].dropna(axis=0)]\n",
    "    BI_word=[nlp(text) for text in keyword_dict[\"BI Tools\"].dropna(axis=0)]\n",
    "    dataeng_word=[nlp(text) for text in keyword_dict[\"Data Engineering\"].dropna(axis=0)]\n",
    "    big_word=[nlp(text) for text in keyword_dict[\"BigData\"].dropna(axis=0)]\n",
    "    \n",
    "    matcher=PhraseMatcher(nlp.vocab)\n",
    "    matcher.add('TimeSeries',None,*time_word)\n",
    "    matcher.add('BI_Tools',None,*BI_word)\n",
    "    matcher.add('R',None,*r_word)\n",
    "    matcher.add('NLP',None,*nlp_word)\n",
    "    matcher.add('Bigdata',None,*big_word)\n",
    "    matcher.add('Machine_learning',None,*ml_word)\n",
    "    matcher.add('Python',None,*python_word)\n",
    "    matcher.add('DeepLearning',None,*dl_word)\n",
    "    matcher.add('DataEngineering',None,*dataeng_word)\n",
    "    doc=nlp(text)\n",
    "    \n",
    "    d=[]\n",
    "    matches=matcher(doc)\n",
    "    for match_id,start,end in matches:\n",
    "        rule_id=nlp.vocab.strings[match_id]\n",
    "        span=doc[start:end]\n",
    "        d.append((rule_id,span.text))\n",
    "    keywords=\"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
    "    \n",
    "    df=pd.read_csv(StringIO(keywords),names=['Keywords_list'])\n",
    "    \n",
    "    df1=pd.DataFrame(df.Keywords_list.str.split(' ',1).tolist(),columns=['Subject','Keyword'])\n",
    "    df2=pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns=['Keyword','Count'])\n",
    "    df3=pd.concat([df1['Subject'],df2['Keyword'],df2['Count']],axis=1)\n",
    "    df3['Count']=df3['Count'].apply(lambda x:x.rstrip(\")\"))\n",
    "    #print(df)\n",
    "    #print(df1)\n",
    "    #print(df2)\n",
    "    #print(df3)\n",
    "    base=os.path.basename(file)\n",
    "    filename=os.path.splitext(base)[0]\n",
    "    name = filename.split('_')\n",
    "    name2 = name[0]\n",
    "    name2 = name2.lower()\n",
    "    ## converting str to dataframe\n",
    "    name3 = pd.read_csv(StringIO(name2),names = ['Candidate Name'])\n",
    "    \n",
    "    dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
    "    #return text\n",
    "    return(dataf)\n",
    "    #return \"Generating candidate skill profile\"\n",
    "def get_report(folder,ontol):\n",
    "   \n",
    "    mypath=folder\n",
    "    onlyfiles=[os.path.join(mypath,f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath,f))]\n",
    "    #print(onlyfiles)\n",
    "    onto=str(ontol)\n",
    "  \n",
    "    \n",
    "    #print(onto)\n",
    "    #print(len(onlyfiles))\n",
    "    currentDT = datetime.datetime.now()\n",
    "    currentDT=currentDT.strftime(\"%Y%m%d%H%M%S\")\n",
    "    final_database=pd.DataFrame()\n",
    "    i = 0 \n",
    "    print(\"--------------------\")\n",
    "    while i < len(onlyfiles):\n",
    "        file = onlyfiles[i]\n",
    "        dat = createProfile(file,onto)\n",
    "        print(dat)\n",
    "        final_database = final_database.append(dat)\n",
    "        i +=1\n",
    "    \n",
    "    yield \"loop passed success..\" + \"\\n\"\n",
    "    #return final_database\n",
    "    final_database2 = final_database['Keyword'].groupby([final_database['Candidate Name'], final_database['Subject']]).count().unstack()\n",
    "    final_database2.reset_index(inplace = True)\n",
    "    final_database2.fillna(0,inplace=True)\n",
    "    #print(final_database2)\n",
    "    yield \"Creating Database for candidates...\" +\"\\n\"\n",
    "    excelmat=\"CandidateSkillExcel\"+str(currentDT)+\".xlsx\"\n",
    "    writer = ExcelWriter(excelmat)\n",
    "    final_database2.to_excel(writer,'resume_skill_Sheet')\n",
    "    writer.save()\n",
    "    #final_database2 = final_database['Keyword'].groupby([final_database['Candidate Name'], final_database['Subject']]).count().unstack()\n",
    "    #final_database2.reset_index(inplace = True)\n",
    "    #final_database2.fillna(0,inplace=True)\n",
    "    new_data = final_database2.iloc[:,1:]\n",
    "    new_data.index = final_database2['Candidate Name']\n",
    "    #execute the below line if you want to see the candidate profile in a csv format\n",
    "    yield \"Generating CSV for candidates...\" +\"\\n\"\n",
    "    csvdata=\"CandidateSkillcsv\"+str(currentDT)+\".csv\"\n",
    "    sample2=new_data.to_csv(csvdata)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    ax = new_data.plot.barh(title=\"Resume keywords by category\", legend=False, figsize=(30,17), stacked=True)\n",
    "    labels = []\n",
    "    for j in new_data.columns:\n",
    "        for i in new_data.index:\n",
    "            label = str(j)+\": \" + str(new_data.loc[i][j])\n",
    "            labels.append(label)\n",
    "    patches = ax.patches\n",
    "    for label, rect in zip(labels, patches):\n",
    "        width = rect.get_width()\n",
    "        if width > 0:\n",
    "            x = rect.get_x()\n",
    "            y = rect.get_y()\n",
    "            height = rect.get_height()\n",
    "            ax.text(x + width/2., y + height/2., label, ha='center', va='center')\n",
    "    mypng=\"Resume_Statistic\"+str(currentDT)+\".png\"\n",
    "    plt.savefig(mypng)\n",
    "    print(\"Saved sucessfully\")\n",
    "    print(\"Profile Generated\")\n",
    "    print(\"Excel Matrix Stored in:\" + str(excelmat))\n",
    "    print(\"Candidate CSV generated ->\" + str(csvdata))\n",
    "    print(\"Skill Static Visualization generated -> \" + str(excelmat))\n",
    "    yield \"Saved sucessfully\" +\"\\n\"\n",
    "    yield \"Profile Generated\" +\"\\n\"\n",
    "    yield \"Excel Matrix Stored in:\" + str(excelmat) +\"\\n\"\n",
    "    yield \"Candidate CSV generated ->\" + str(csvdata) +\"\\n\"\n",
    "    yield \"Skill Visualization generated -> \" + str(mypng) +\"\\n\"\n",
    "    yield \"Done\" +\"\\n\"\n",
    "    #return final_database2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mypath=\"Analytics_hire\"\n",
    "#ontol='datascience_ontology.csv'\n",
    "#onlyfiles=[os.path.join(mypath,f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath,f))]\n",
    "#rep=get_report(mypath,ontol)\n",
    "#createProfile(onlyfiles[0],ontol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for value in rep:\n",
    "#    print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import scrolledtext\n",
    "from tkinter import Menu\n",
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "\n",
    "from tkinter.filedialog import askopenfilename\n",
    "win=tk.Tk()\n",
    "win.title(\"Candidate Resume Parsing\")\n",
    "win.geometry(\"600x400\")\n",
    "win.resizable(0,0)\n",
    "scrolw=72\n",
    "scrolh=19\n",
    "\n",
    "#scroll\n",
    "scr=scrolledtext.ScrolledText(win,width=scrolw, height=scrolh, wrap=tk.WORD)\n",
    "scr.grid(row=5,column=0)\n",
    "\n",
    "def _quit(): # 7\n",
    "    win.quit()\n",
    "    win.destroy()\n",
    "    exit()\n",
    "\n",
    "def data1():\n",
    "    scr.insert(END,\"Adding resume folder and Skill Ontology\" + \"\\n\")\n",
    "    scr.insert(END,\"Loading...Please Wait\" + \"\\n\")\n",
    "    \n",
    "    mypath=fldr()\n",
    "    ttk.Label(labelframe,text=mypath).grid(column=0, row=0,padx=10, pady=10)\n",
    "    onlyfiles=[os.path.join(mypath,f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath,f))]\n",
    "    print(len(onlyfiles))\n",
    "    onto=adddict()\n",
    "    ttk.Label(labelframe,text=onto).grid(column=0, row=1,padx=10, pady=10)\n",
    "    scr.insert(END,\"Generating Candidate Profile..\" + \" \\n\")\n",
    "    d=get_report(mypath,onto)\n",
    "   \n",
    "    for values in d:\n",
    "        scr.insert(END,str(values))\n",
    "    #print(d)\n",
    "\n",
    "\n",
    "def adddict():\n",
    "    folder_selected = askopenfilename()\n",
    "    fold1=str(folder_selected) \n",
    "    #print(fold1)\n",
    "    #d1=ttk.Label(labelframe,text=fold1).grid(column=0, row=1,padx=10, pady=10)\n",
    "    return fold1\n",
    "\n",
    "\n",
    "lab=ttk.Label(win,text=\"\")\n",
    "lab.grid(column=0, row=0)\n",
    "\n",
    "def fldr(): \n",
    "    folder_selected = filedialog.askdirectory()\n",
    "    fold=str(folder_selected) \n",
    "    print(fold)\n",
    "    #ttk.Label(labelframe,text=fold).grid(column=0, row=2,padx=10, pady=10)\n",
    "    return fold\n",
    "\n",
    "def helpp():\n",
    "    messagebox.showinfo(\"Help\", \"\"\"Step 1: Add the candidate resume folder \\nStep 2: Add the skill lookup Dictionary \\nWait for Exection \\nDone \"\"\")\n",
    "\n",
    "\n",
    "#menubar\n",
    "Menubar=Menu(win)\n",
    "win.config(menu=Menubar)\n",
    "filemenu=Menu(Menubar,tearoff=0)\n",
    "filemenu.add_command(label='Get Report',command=data1)\n",
    "#filemenu.add_command(label='',command=adddict)\n",
    "#filemenu.add_command(label='',command=fldr)\n",
    "filemenu.add_command(label='Exit',command=_quit)\n",
    "Menubar.add_cascade(label=\"File\",menu=filemenu)\n",
    "#adding about\n",
    "filemenu1=Menu(Menubar,tearoff=0)\n",
    "filemenu1.add_command(label='Help',command=helpp)\n",
    "Menubar.add_cascade(label=\"About\",menu=filemenu1)\n",
    "\n",
    "labelframe=ttk.LabelFrame(win,text=\"File Information\")\n",
    "labelframe.grid(column=0, row=0 ,padx=10, pady=40)\n",
    "\n",
    "#place label\n",
    "#lbl1=ttk.Label(labelframe,text=\"hello\").grid(column=0, row=0 ,padx=10, pady=10)\n",
    "#lbl2=ttk.Label(labelframe,text=\"world\").grid(column=1, row=0,padx=10, pady=10)\n",
    "#lbl3=ttk.Label(labelframe,text=\"siraj\").grid(column=2, row=0,padx=10, pady=10)\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
